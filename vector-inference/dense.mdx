---
title: 'Using Custom Models'
icon: brackets-curly
description: How to use gated or private models hosted on Hugging Face
mode: wide
---

## Custom or fine tuned models in Trieve Vector Inference

The [open source text models](https://huggingface.co/spaces/mteb/leaderboard) on Hugging Face may not be what you always want, 


<Steps>
<Step title="Update embedding_models.yaml">
To use a private or custom model with Trieve Vector Inference, you will need to update your `embedding_models.yaml` file.

If the model is a private or gated Hugging Face model, you will need to include your Hugging Face API token.

```yaml embedding_models.yaml
...
models:
  ...
  my-custom-model:
    replicas: 1
    revision: main
    modelName: trieve/private-model-example
	hfToken: "hf_**********************************"
...
```
</Step>

<Step title="Update your TVI cluster">
Update TVI to include your models

```bash
helm upgrade -i vector-inference \
    oci://709825985650.dkr.ecr.us-east-1.amazonaws.com/trieve/trieve-embeddings  \
    -f embedding_models.yaml
```
</Step>

<Step title="Get embeddings endpoint">
```sh
kubectl get ing
```
</Step>
</Steps>

