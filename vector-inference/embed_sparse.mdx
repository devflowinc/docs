---
title: 'Create Sparse Embedding'
sidebarTitle: 'POST /embed_sparse'
description: 'Get sparse embeddings. Returns a 424 status code if the model is not a SPLADE embedding model'
---

Generating an embedding from a sparse embedding model.
The main ones that we support are SPLADE models.

<RequestExample>

```json RAW Json
{
  "inputs": "The model input",
  "prompt_name": null,
  "truncate": false,
  "truncation_direction": "right"
}
```

```sh curl
curl -X POST \
     -H "Content-Type: application/json"\
     -d '{"inputs": "test input"}' \
     --url http://$ENDPOINT/embed_sparse
```

```py python
import requests

endpoint = "<your-custom-endpoint>"

requests.post(f"{endpoint}/embed_sparse", json={
    "inputs": ["test input", "test input 2"]
});

## or 

requests.post(f"{endpoint}/embed_sparse", json={
    "inputs": "test single input"
});


```

</RequestExample>

<ResponseExample>
```json 200 Embeddings
[
    // Embedding 1
    [
        {
            "index": 1012,
            "value": 0.9970703
        },
        {
            "index": 4456,
            "value": 2.7832031
        }
    ],
    // Embedding 2
    [
        {
            "index": 990,
            "value": 2.783203
        },
        {
            "index": 3021,
            "value": 10.9970703
        },
        ...
    ],
    ...
]
```

```json 413
{
    "error": "Batch size error",
    "error_type": "validation"
}
```

```json 422
{
    "error": "Tokenization error",
    "error_type": "validation"
}
```

```json 424
{
    "error": "Inference failed",
    "error_type": "backend"
}
```

```json 429
{
    "error": "Model is overloaded",
    "error_type": "overloaded"
}
```
</ResponseExample>



<ParamField path="inputs" type="string | string[]" required>
  Inputs that need to be embedded
</ParamField>

<ParamField path="prompt_name" type="string">
The name of the prompt that should be used by for encoding. If not set, no prompt will be applied.

Must be a key in the `sentence-transformers` configuration prompts dictionary.

For example if `prompt_name` is **"doc"** then the sentence **"How to get fast inference?"** will be encoded as **"doc: How to get fast inference?"** because the prompt text will be prepended before any text to encode.
</ParamField>

<ParamField path="truncate" type="boolean" default="false">
Automatically truncate inputs that are longer than the maximum supported size
</ParamField>

<ParamField path="truncate_direction" type='"right" | "left"' default="right">
</ParamField>

